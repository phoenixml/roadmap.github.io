@article{li2020backdoor,
  title={Backdoor learning: A survey},
  author={Li, Yiming and Wu, Baoyuan and Jiang, Yong and Li, Zhifeng and Xia, Shu-Tao},
  journal={arXiv preprint arXiv:2007.08745},
  year={2020}
}
@misc{fang2020backdoor,
      title={Backdoor Attacks on the DNN Interpretation System}, 
      author={Shihong Fang and Anna Choromanska},
      year={2020},
      eprint={2011.10698},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}

@misc{moitra2020exposing,
      title={Exposing the Robustness and Vulnerability of Hybrid 8T-6T SRAM Memory Architectures to Adversarial Attacks in Deep Neural Networks}, 
      author={Abhishek Moitra and Priyadarshini Panda},
      year={2020},
      eprint={2011.13392},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}

@article{li2016persona,
  title={A persona-based neural conversation model},
  author={Li, Jiwei and Galley, Michel and Brockett, Chris and Spithourakis, Georgios P and Gao, Jianfeng and Dolan, Bill},
  journal={arXiv preprint arXiv:1603.06155},
  year={2016}
}

@article{newsome2012mindfulness,
  title={Mindfulness group work: Preventing stress and increasing self-compassion among helping professionals in training},
  author={Newsome, Sandy and Waldo, Michael and Gruszka, Clare},
  journal={The Journal for Specialists in Group Work},
  volume={37},
  number={4},
  pages={297--311},
  year={2012},
  publisher={Taylor \& Francis}
}


@misc{li2020bertattack,
      title={BERT-ATTACK: Adversarial Attack Against BERT Using BERT}, 
      author={Linyang Li and Ruotian Ma and Qipeng Guo and Xiangyang Xue and Xipeng Qiu},
      year={2020},
      eprint={2004.09984},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{li2020backdoor,
  title={Backdoor learning: A survey},
  author={Li, Yiming and Wu, Baoyuan and Jiang, Yong and Li, Zhifeng and Xia, Shu-Tao},
  journal={arXiv preprint arXiv:2007.08745},
  year={2020}
}

@inproceedings{quiring2020adversarial,
  title={Adversarial Preprocessing: Understanding and Preventing Image-Scaling Attacks in Machine Learning},
  author={Quiring, Erwin and Klein, David and Arp, Daniel and Johns, Martin and Rieck, Konrad},
  booktitle={29th $\{$USENIX$\}$ Security Symposium ($\{$USENIX$\}$ Security 20)},
  year={2020}
}

@article{gurbaxani2018traits,
  title={Traits \& Transferability of Adversarial Examples against Instance Segmentation \& Object Detection},
  author={Gurbaxani, Raghav and Mishra, Shivank},
  journal={arXiv preprint arXiv:1808.01452},
  year={2018}
}


@incollection{fontenla2013online,
  title={Online machine learning},
  author={Fontenla-Romero, {\'O}scar and Guijarro-Berdi{\~n}as, Bertha and Martinez-Rego, David and P{\'e}rez-S{\'a}nchez, Beatriz and Peteiro-Barral, Diego},
  booktitle={Efficiency and Scalability Methods for Computational Intellect},
  pages={27--54},
  year={2013},
  publisher={IGI Global}
}


@misc{croce2020reliable,
      title={Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks}, 
      author={Francesco Croce and Matthias Hein},
      year={2020},
      eprint={2003.01690},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{ghiasi2020breaking,
      title={Breaking certified defenses: Semantic adversarial examples with spoofed robustness certificates}, 
      author={Amin Ghiasi and Ali Shafahi and Tom Goldstein},
      year={2020},
      eprint={2003.08937},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{he2019parametric,
  title={Parametric noise injection: Trainable randomness to improve deep neural network robustness against adversarial attack},
  author={He, Zhezhi and Rakin, Adnan Siraj and Fan, Deliang},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={588--597},
  year={2019}
}

@article{milton2018evaluation,
  title={Evaluation of momentum diverse input iterative fast gradient sign method (m-di2-fgsm) based attack method on mcs 2018 adversarial attacks on black box face recognition system},
  author={Milton, Md Ashraful Alam},
  journal={arXiv preprint arXiv:1806.08970},
  year={2018}
}

@inproceedings{croce2018randomized,
  title={A randomized gradient-free attack on relu networks},
  author={Croce, Francesco and Hein, Matthias},
  booktitle={German Conference on Pattern Recognition},
  pages={215--227},
  year={2018},
  organization={Springer}
}
@article{cheng2018query,
  title={Query-efficient hard-label black-box attack: An optimization-based approach},
  author={Cheng, Minhao and Le, Thong and Chen, Pin-Yu and Yi, Jinfeng and Zhang, Huan and Hsieh, Cho-Jui},
  journal={arXiv preprint arXiv:1807.04457},
  year={2018}
}

@article{xie2019adding,
  title={Adding Gaussian Noise to DeepFool for Robustness based on Perturbation Directionality.},
  author={Xie, Tianying and Li, Yantao},
  journal={Aust. J. Intell. Inf. Process. Syst.},
  volume={16},
  number={3},
  pages={44--54},
  year={2019}
}

@article{yakhyaeva2014application,
  title={Application of case-based methodology for early diagnosis of computer attacks},
  author={Yakhyaeva, Gulnara and Yasinskaya, Olga},
  journal={Journal of computing and information technology},
  volume={22},
  number={3},
  pages={145--150},
  year={2014},
  publisher={SRCE-Sveu{\v{c}}ili{\v{s}}ni ra{\v{c}}unski centar}
}

@article{lopes2019improving,
  title={Improving robustness without sacrificing accuracy with patch gaussian augmentation},
  author={Lopes, Raphael Gontijo and Yin, Dong and Poole, Ben and Gilmer, Justin and Cubuk, Ekin D},
  journal={arXiv preprint arXiv:1906.02611},
  year={2019}
}
@article{huang2020adversarial,
  title={Adversarial attacks on deep-learning-based SAR image target recognition},
  author={Huang, Teng and Zhang, Qixiang and Liu, Jiabao and Hou, Ruitao and Wang, Xianmin and Li, Ya},
  journal={Journal of Network and Computer Applications},
  pages={102632},
  year={2020},
  publisher={Elsevier}
}
@inproceedings{sharma2018attend,
  title={Attend and attack: Attention guided adversarial attacks on visual question answering models},
  author={Sharma, Vasu and Kalra, Ankita and Vaibhav, Simral Chaudhary and Patel, Labhesh and Morency, Louis-Phillippe},
  booktitle={Proc. Conf. Neural Inf. Process. Syst. Workshop Secur. Mach. Learn},
  year={2018}
}

@inproceedings{naseer2019cross,
  title={Cross-domain transferability of adversarial perturbations},
  author={Naseer, Muhammad Muzammal and Khan, Salman H and Khan, Muhammad Haris and Khan, Fahad Shahbaz and Porikli, Fatih},
  booktitle={Advances in Neural Information Processing Systems},
  pages={12905--12915},
  year={2019}
}

@inproceedings{shao2019multi,
  title={Multi-adversarial discriminative deep domain generalization for face presentation attack detection},
  author={Shao, Rui and Lan, Xiangyuan and Li, Jiawei and Yuen, Pong C},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={10023--10031},
  year={2019}
}
@article{kurita2020weight,
  title={Weight poisoning attacks on pre-trained models},
  author={Kurita, Keita and Michel, Paul and Neubig, Graham},
  journal={arXiv preprint arXiv:2004.06660},
  year={2020}
}
@inproceedings{dong2018boosting,
  title={Boosting adversarial attacks with momentum},
  author={Dong, Yinpeng and Liao, Fangzhou and Pang, Tianyu and Su, Hang and Zhu, Jun and Hu, Xiaolin and Li, Jianguo},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={9185--9193},
  year={2018}
}

@article{lindqvist2020minimax,
  title={Minimax Defense against Gradient-based Adversarial Attacks},
  author={Lindqvist, Blerta and Izmailov, Rauf},
  journal={arXiv preprint arXiv:2002.01256},
  year={2020}
}
@article{sun2018data,
  title={Data poisoning attack against unsupervised node embedding methods},
  author={Sun, Mingjie and Tang, Jian and Li, Huichen and Li, Bo and Xiao, Chaowei and Chen, Yao and Song, Dawn},
  journal={arXiv preprint arXiv:1810.12881},
  year={2018}
}
@inproceedings{shokri2017membership,
  title={Membership inference attacks against machine learning models},
  author={Shokri, Reza and Stronati, Marco and Song, Congzheng and Shmatikov, Vitaly},
  booktitle={2017 IEEE Symposium on Security and Privacy (SP)},
  pages={3--18},
  year={2017},
  organization={IEEE}
}
@article{wong2019wasserstein,
  title={Wasserstein adversarial examples via projected sinkhorn iterations},
  author={Wong, Eric and Schmidt, Frank R and Kolter, J Zico},
  journal={arXiv preprint arXiv:1902.07906},
  year={2019}
}
@inproceedings{hendrik2017universal,
  title={Universal adversarial perturbations against semantic image segmentation},
  author={Hendrik Metzen, Jan and Chaithanya Kumar, Mummadi and Brox, Thomas and Fischer, Volker},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={2755--2764},
  year={2017}
}

  
  @misc{akhtar2018threat,
      title={Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey}, 
      author={Naveed Akhtar and Ajmal Mian},
      year={2018}
}
  
  @article{wang2019dynamic,
  title={Dynamic data injection attack detection of cyber physical power systems with uncertainties},
  author={Wang, Huaizhi and Ruan, Jiaqi and Zhou, Bin and Li, Canbing and Wu, Qiuwei and Raza, Muhammad Qamar and Cao, Guang-Zhong},
  journal={IEEE Transactions on Industrial Informatics},
  volume={15},
  number={10},
  pages={5505--5518},
  year={2019},
  publisher={IEEE}
}

@article{rauber2017foolbox,
  title={Foolbox: A python toolbox to benchmark the robustness of machine learning models},
  author={Rauber, Jonas and Brendel, Wieland and Bethge, Matthias},
  journal={arXiv preprint arXiv:1707.04131},
  year={2017}
}
@article{liu2018dpatch,
  title={Dpatch: An adversarial patch attack on object detectors},
  author={Liu, Xin and Yang, Huanrui and Liu, Ziwei and Song, Linghao and Li, Hai and Chen, Yiran},
  journal={arXiv preprint arXiv:1806.02299},
  year={2018}
}
@inproceedings{chen2018shapeshifter,
  title={Shapeshifter: Robust physical adversarial attack on faster r-cnn object detector},
  author={Chen, Shang-Tse and Cornelius, Cory and Martin, Jason and Chau, Duen Horng Polo},
  booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},
  pages={52--68},
  year={2018},
  organization={Springer}
}
@article{nicolae2018adversarial,
  title={Adversarial Robustness Toolbox v1. 0.0},
  author={Nicolae, Maria-Irina and Sinn, Mathieu and Tran, Minh Ngoc and Buesser, Beat and Rawat, Ambrish and Wistuba, Martin and Zantedeschi, Valentina and Baracaldo, Nathalie and Chen, Bryant and Ludwig, Heiko and others},
  journal={arXiv preprint arXiv:1807.01069},
  year={2018}
}
@article{chen2017ead,
  title={Ead: elastic-net attacks to deep neural networks via adversarial examples},
  author={Chen, Pin-Yu and Sharma, Yash and Zhang, Huan and Yi, Jinfeng and Hsieh, Cho-Jui},
  journal={arXiv preprint arXiv:1709.04114},
  year={2017}
}
@inproceedings{thys2019fooling,
  title={Fooling automated surveillance cameras: adversarial patches to attack person detection},
  author={Thys, Simen and Van Ranst, Wiebe and Goedem{\'e}, Toon},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  pages={0--0},
  year={2019}
}
@article{liu2018dpatch,
  title={Dpatch: An adversarial patch attack on object detectors},
  author={Liu, Xin and Yang, Huanrui and Liu, Ziwei and Song, Linghao and Li, Hai and Chen, Yiran},
  journal={arXiv preprint arXiv:1806.02299},
  year={2018}
}

@article{wiyatno2018maximal,
  title={Maximal jacobian-based saliency map attack},
  author={Wiyatno, Rey and Xu, Anqi},
  journal={arXiv preprint arXiv:1808.07945},
  year={2018}
}
@inproceedings{li2019universal,
  title={Universal perturbation attack against image retrieval},
  author={Li, Jie and Ji, Rongrong and Liu, Hong and Hong, Xiaopeng and Gao, Yue and Tian, Qi},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={4899--4908},
  year={2019}
}
@inproceedings{suciu2018does,
  title={When does machine learning $\{$FAIL$\}$? generalized transferability for evasion and poisoning attacks},
  author={Suciu, Octavian and Marginean, Radu and Kaya, Yigitcan and Daume III, Hal and Dumitras, Tudor},
  booktitle={27th $\{$USENIX$\}$ Security Symposium ($\{$USENIX$\}$ Security 18)},
  pages={1299--1316},
  year={2018}
}
@article{deng2019batch,
  title={Batch virtual adversarial training for graph convolutional networks},
  author={Deng, Zhijie and Dong, Yinpeng and Zhu, Jun},
  journal={arXiv preprint arXiv:1902.09192},
  year={2019}
}
@article{chen2018fast,
  title={Fast gradient attack on network embedding},
  author={Chen, Jinyin and Wu, Yangyang and Xu, Xuanheng and Chen, Yixian and Zheng, Haibin and Xuan, Qi},
  journal={arXiv preprint arXiv:1809.02797},
  year={2018}
}
@inproceedings{papernot2017practical,
  title={Practical black-box attacks against machine learning},
  author={Papernot, Nicolas and McDaniel, Patrick and Goodfellow, Ian and Jha, Somesh and Celik, Z Berkay and Swami, Ananthram},
  booktitle={Proceedings of the 2017 ACM on Asia conference on computer and communications security},
  pages={506--519},
  year={2017}
}
@inproceedings{wang2018stealing,
  title={Stealing hyperparameters in machine learning},
  author={Wang, Binghui and Gong, Neil Zhenqiang},
  booktitle={2018 IEEE Symposium on Security and Privacy (SP)},
  pages={36--52},
  year={2018},
  organization={IEEE}
}

@article{nicolae2018adversarial,
  title={Adversarial Robustness Toolbox v1. 0.0},
  author={Nicolae, Maria-Irina and Sinn, Mathieu and Tran, Minh Ngoc and Buesser, Beat and Rawat, Ambrish and Wistuba, Martin and Zantedeschi, Valentina and Baracaldo, Nathalie and Chen, Bryant and Ludwig, Heiko and others},
  journal={arXiv preprint arXiv:1807.01069},
  year={2018}
}
@article{nelson2008exploiting,
  title={Exploiting Machine Learning to Subvert Your Spam Filter.},
  author={Nelson, Blaine and Barreno, Marco and Chi, Fuching Jack and Joseph, Anthony D and Rubinstein, Benjamin IP and Saini, Udam and Sutton, Charles A and Tygar, J Doug and Xia, Kai},
  journal={LEET},
  volume={8},
  pages={1--9},
  year={2008}
}

@article{guo2019simple,
  title={Simple black-box adversarial attacks},
  author={Guo, Chuan and Gardner, Jacob R and You, Yurong and Wilson, Andrew Gordon and Weinberger, Kilian Q},
  journal={arXiv preprint arXiv:1905.07121},
  year={2019}
}

@article{xiao2018spatially,
  title={Spatially transformed adversarial examples},
  author={Xiao, Chaowei and Zhu, Jun-Yan and Li, Bo and He, Warren and Liu, Mingyan and Song, Dawn},
  journal={arXiv preprint arXiv:1801.02612},
  year={2018}
}
@article{cheng2018query,
  title={Query-efficient hard-label black-box attack: An optimization-based approach},
  author={Cheng, Minhao and Le, Thong and Chen, Pin-Yu and Yi, Jinfeng and Zhang, Huan and Hsieh, Cho-Jui},
  journal={arXiv preprint arXiv:1807.04457},
  year={2018}
}
@inproceedings{chen2017zoo,
  title={Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models},
  author={Chen, Pin-Yu and Zhang, Huan and Sharma, Yash and Yi, Jinfeng and Hsieh, Cho-Jui},
  booktitle={Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security},
  pages={15--26},
  year={2017}
}
@article{brendel2017decision,
  title={Decision-based adversarial attacks: Reliable attacks against black-box machine learning models},
  author={Brendel, Wieland and Rauber, Jonas and Bethge, Matthias},
  journal={arXiv preprint arXiv:1712.04248},
  year={2017}
}
@inproceedings{shafahi2018poison,
  title={Poison frogs! targeted clean-label poisoning attacks on neural networks},
  author={Shafahi, Ali and Huang, W Ronny and Najibi, Mahyar and Suciu, Octavian and Studer, Christoph and Dumitras, Tudor and Goldstein, Tom},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6103--6113},
  year={2018}
}

@article{jagielski2019high,
  title={High-fidelity extraction of neural network models},
  author={Jagielski, Matthew and Carlini, Nicholas and Berthelot, David and Kurakin, Alex and Papernot, Nicolas},
  journal={arXiv preprint arXiv:1909.01838},
  year={2019}
}
@inproceedings{correia2018copycat,
  title={Copycat cnn: Stealing knowledge by persuading confession with random non-labeled data},
  author={Correia-Silva, Jacson Rodrigues and Berriel, Rodrigo F and Badue, Claudine and de Souza, Alberto F and Oliveira-Santos, Thiago},
  booktitle={2018 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--8},
  year={2018},
  organization={IEEE}
}
@inproceedings{orekondy2019knockoff,
  title={Knockoff nets: Stealing functionality of black-box models},
  author={Orekondy, Tribhuvanesh and Schiele, Bernt and Fritz, Mario},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4954--4963},
  year={2019}
}
@article{ozay2015machine,
  title={Machine learning methods for attack detection in the smart grid},
  author={Ozay, Mete and Esnaola, Inaki and Vural, Fatos Tunay Yarman and Kulkarni, Sanjeev R and Poor, H Vincent},
  journal={IEEE transactions on neural networks and learning systems},
  volume={27},
  number={8},
  pages={1773--1786},
  year={2015},
  publisher={IEEE}
}

@article{yuanblack,
  title={Black-box Adversarial Attacks Against Deep Learning Based Malware Binaries Detection with GAN},
  author={Yuan, Junkun and Zhou, Shaofang and Lin, Lanfen and Wang, Feng and Cui, Jia}
}

@article{chen2018automated,
  title={Automated poisoning attacks and defenses in malware detection systems: An adversarial machine learning approach},
  author={Chen, Sen and Xue, Minhui and Fan, Lingling and Hao, Shuang and Xu, Lihua and Zhu, Haojin and Li, Bo},
  journal={computers \& security},
  volume={73},
  pages={326--344},
  year={2018},
  publisher={Elsevier}
}

@article{anderson2017evading,
  title={Evading machine learning malware detection},
  author={Anderson, Hyrum S and Kharkar, Anant and Filar, Bobby and Roth, Phil},
  journal={Black Hat},
  year={2017}
}

@article{vorobeychik2018adversarial,
  title={Adversarial machine learning},
  author={Vorobeychik, Yevgeniy and Kantarcioglu, Murat},
  journal={Synthesis Lectures on Artificial Intelligence and Machine Learning},
  volume={12},
  number={3},
  pages={1--169},
  year={2018},
  publisher={Morgan \& Claypool Publishers}
}

@article{chen2019adversarial,
  title={Adversarial examples for CNN-based malware detectors},
  author={Chen, Bingcai and Ren, Zhongru and Yu, Chao and Hussain, Iftikhar and Liu, Jintao},
  journal={IEEE Access},
  volume={7},
  pages={54360--54371},
  year={2019},
  publisher={IEEE}
}

@article{wu2019detecting,
  title={Detecting cyber-physical attacks in CyberManufacturing systems with machine learning methods},
  author={Wu, Mingtao and Song, Zhengyi and Moon, Young B},
  journal={Journal of intelligent manufacturing},
  volume={30},
  number={3},
  pages={1111--1123},
  year={2019},
  publisher={Springer}
}

@inproceedings{hink2014machine,
  title={Machine learning for power system disturbance and cyber-attack discrimination},
  author={Hink, Raymond C Borges and Beaver, Justin M and Buckner, Mark A and Morris, Tommy and Adhikari, Uttam and Pan, Shengyi},
  booktitle={2014 7th International symposium on resilient control systems (ISRCS)},
  pages={1--8},
  year={2014},
  organization={IEEE}
}
@inproceedings{GradientEpisodicMemory,
    title={Gradient Episodic Memory for Continual Learning},
    author={Lopez-Paz, David and Ranzato, Marc'Aurelio},
    booktitle={NIPS},
    year={2017}
}

@article{yuanblack,
  title={Black-box Adversarial Attacks Against Deep Learning Based Malware Binaries Detection with GAN},
  author={Yuan, Junkun and Zhou, Shaofang and Lin, Lanfen and Wang, Feng and Cui, Jia}
}

@inproceedings{pengcheng2018query,
  title={Query-efficient black-box attack by active learning},
  author={Pengcheng, Li and Yi, Jinfeng and Zhang, Lijun},
  booktitle={2018 IEEE International Conference on Data Mining (ICDM)},
  pages={1200--1205},
  year={2018},
  organization={IEEE}
}

@article{takemura2020model,
  title={Model Extraction Attacks against Recurrent Neural Networks},
  author={Takemura, Tatsuya and Yanai, Naoto and Fujiwara, Toru},
  journal={arXiv preprint arXiv:2002.00123},
  year={2020}
}

@misc{cosgrove2020robustness,
      title={Robustness Out of the Box: Compositional Representations Naturally Defend Against Black-Box Patch Attacks}, 
      author={Christian Cosgrove and Adam Kortylewski and Chenglin Yang and Alan Yuille},
      year={2020},
      eprint={2012.00558},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{yin2020improving,
      title={Improving the Transferability of Adversarial Examples with the Adam Optimizer}, 
      author={Heng Yin and Hengwei Zhang and Jindong Wang and Ruiyu Dou},
      year={2020},
      eprint={2012.00567},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{moosavidezfooli2016deepfool,
      title={DeepFool: a simple and accurate method to fool deep neural networks}, 
      author={Seyed-Mohsen Moosavi-Dezfooli and Alhussein Fawzi and Pascal Frossard},
      year={2016},
      eprint={1511.04599},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{tramèr2020ensemble,
      title={Ensemble Adversarial Training: Attacks and Defenses}, 
      author={Florian Tramèr and Alexey Kurakin and Nicolas Papernot and Ian Goodfellow and Dan Boneh and Patrick McDaniel},
      year={2020},
      eprint={1705.07204},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@inproceedings{arnab_cvpr_2018,
	title={On the Robustness of Semantic Segmentation Models to Adversarial Attacks},
	author={Arnab, Anurag and Miksik, Ondrej and Torr, Philip H. S.},
	booktitle={CVPR},
	year={2018}
}

@article{jia2014caffe,
  Author = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},
  Journal = {arXiv preprint arXiv:1408.5093},
  Title = {Caffe: Convolutional Architecture for Fast Feature Embedding},
  Year = {2014}
}

@misc{wang2018data,
      title={Data Poisoning Attacks against Online Learning}, 
      author={Yizhen Wang and Kamalika Chaudhuri},
      year={2018},
      eprint={1808.08994},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{wang2020investigation,
      title={An Investigation of Data Poisoning Defenses for Online Learning}, 
      author={Yizhen Wang and Somesh Jha and Kamalika Chaudhuri},
      year={2020},
      eprint={1905.12121},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{wang2020defending,
      title={Defending against Adversarial Attack towards Deep Neural Networks via Collaborative Multi-task Training}, 
      author={Derek Wang and Chaoran Li and Sheng Wen and Surya Nepal and Yang Xiang},
      year={2020},
      eprint={1803.05123},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@ARTICLE{9096397,
  author={X. {Hu} and Y. {Zhao} and L. {Deng} and L. {Liang} and P. {Zuo} and J. {Ye} and Y. {Lin} and Y. {Xie}},
  journal={IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems}, 
  title={Practical Attacks on Deep Neural Networks by Memory Trojaning}, 
  year={2020},
  volume={},
  number={},
  pages={1-1},
  doi={10.1109/TCAD}}
  
  @INPROCEEDINGS{8473440,
author={N. {Baracaldo} and B. {Chen} and H. {Ludwig} and A. {Safavi} and R. {Zhang}},
booktitle={2018 IEEE International Congress on Internet of Things (ICIOT)}, title={Detecting Poisoning Attacks on Machine Learning in IoT Environments},
year={2018},
volume={},
number={},
pages={57-64},
doi={10.1109/ICIOT.2018.00015}}

@article{Biggio_2013,
   title={Evasion Attacks against Machine Learning at Test Time},
   ISBN={9783642387098},
   ISSN={1611-3349},
   url={http://dx.doi.org/10.1007/978-3-642-40994-3_25},
   DOI={10.1007/978-3-642-40994-3_25},
   journal={Lecture Notes in Computer Science},
   publisher={Springer Berlin Heidelberg},
   author={Biggio, Battista and Corona, Igino and Maiorca, Davide and Nelson, Blaine and Šrndić, Nedim and Laskov, Pavel and Giacinto, Giorgio and Roli, Fabio},
   year={2013},
   pages={387–402}
}
@misc{shumailov2020sponge,
      title={Sponge Examples: Energy-Latency Attacks on Neural Networks}, 
      author={Ilia Shumailov and Yiren Zhao and Daniel Bates and Nicolas Papernot and Robert Mullins and Ross Anderson},
      year={2020},
      eprint={2006.03463},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{madry2017towards,
  title={Towards deep learning models resistant to adversarial attacks},
  author={Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  journal={arXiv preprint arXiv:1706.06083},
  year={2017}
}
@INPROCEEDINGS{8885251,
  author={A. {Abusnaina} and A. {Khormali} and H. {Alasmary} and J. {Park} and A. {Anwar} and A. {Mohaisen}},
  booktitle={2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS)}, 
  title={Adversarial Learning Attacks on Graph-based IoT Malware Detection Systems}, 
  year={2019},
  volume={},
  number={},
  pages={1296-1305},
  doi={10.1109/ICDCS.2019.00130}
  }
  
@article{yuan2019adversarial,
  title={Adversarial examples: Attacks and defenses for deep learning},
  author={Yuan, Xiaoyong and He, Pan and Zhu, Qile and Li, Xiaolin},
  journal={IEEE transactions on neural networks and learning systems},
  volume={30},
  number={9},
  pages={2805--2824},
  year={2019},
  publisher={IEEE}
}
@article{kurakin2016adversarial,
  title={Adversarial examples in the physical world},
  author={Kurakin, Alexey and Goodfellow, Ian and Bengio, Samy},
  journal={arXiv preprint arXiv:1607.02533},
  year={2016}
}
@misc{tabassi2019taxonomy,
  title={A Taxonomy and Terminology of Adversarial Machine Learning},
  author={Tabassi, Elham and Burns, Kevin J and Hadjimichael, Michael and Molina-Markham, Andres D and Sexton, Julian T},
  year={2019},
  publisher={NIST IR}
}
@inproceedings{moosavi2016deepfool,
  title={Deepfool: a simple and accurate method to fool deep neural networks},
  author={Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Frossard, Pascal},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2574--2582},
  year={2016}
}
@inproceedings{tramer2016stealing,
  title={Stealing machine learning models via prediction apis},
  author={Tram{\`e}r, Florian and Zhang, Fan and Juels, Ari and Reiter, Michael K and Ristenpart, Thomas},
  booktitle={25th $\{$USENIX$\}$ Security Symposium ($\{$USENIX$\}$ Security 16)},
  pages={601--618},
  year={2016}
}
@article{goodfellow2014,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}
@article{pattanaik2017robust,
  title={Robust deep reinforcement learning with adversarial attacks},
  author={Pattanaik, Anay and Tang, Zhenyi and Liu, Shuijing and Bommannan, Gautham and Chowdhary, Girish},
  journal={arXiv preprint arXiv:1712.03632},
  year={2017}
}
@inproceedings{jagielski2020high,
  title={High Accuracy and High Fidelity Extraction of Neural Networks},
  author={Jagielski, Matthew and Carlini, Nicholas and Berthelot, David and Kurakin, Alex and Papernot, Nicolas},
  booktitle={29th $\{$USENIX$\}$ Security Symposium ($\{$USENIX$\}$ Security 20)},
  year={2020}
}
@article{croce2020reliable,
  title={Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks},
  author={Croce, Francesco and Hein, Matthias},
  journal={arXiv preprint arXiv:2003.01690},
  year={2020}
}
@article{mosbach2018logit,
  title={Logit pairing methods can fool gradient-based attacks},
  author={Mosbach, Marius and Andriushchenko, Maksym and Trost, Thomas and Hein, Matthias and Klakow, Dietrich},
  journal={arXiv preprint arXiv:1810.12042},
  year={2018}
}
@inproceedings{croce2019provable,
  title={Provable robustness of relu networks via maximization of linear regions},
  author={Croce, Francesco and Andriushchenko, Maksym and Hein, Matthias},
  booktitle={the 22nd International Conference on Artificial Intelligence and Statistics},
  pages={2057--2066},
  year={2019},
  organization={PMLR}
}
@article{SHI2020107309,
title = "Adaptive iterative attack towards explainable adversarial robustness",
journal = "Pattern Recognition",
volume = "105",
pages = "107309",
year = "2020",
issn = "0031-3203",
doi = "https://doi.org/10.1016/j.patcog.2020.107309",
url = "http://www.sciencedirect.com/science/article/pii/S0031320320301138",
author = "Yucheng Shi and Yahong Han and Quanxin Zhang and Xiaohui Kuang",
keywords = "Adversarial example, Adversarial attack, Image classification"
}

@inproceedings{jang2019adversarial,
  title={Adversarial defense via learning to generate diverse attacks},
  author={Jang, Yunseok and Zhao, Tianchen and Hong, Seunghoon and Lee, Honglak},
  booktitle={Proceedings of the IEEE International Conference on Computer Vision},
  pages={2740--2749},
  year={2019}
}
@inproceedings{alzantot2019genattack,
  title={Genattack: Practical black-box attacks with gradient-free optimization},
  author={Alzantot, Moustafa and Sharma, Yash and Chakraborty, Supriyo and Zhang, Huan and Hsieh, Cho-Jui and Srivastava, Mani B},
  booktitle={Proceedings of the Genetic and Evolutionary Computation Conference},
  pages={1111--1119},
  year={2019}
}
@inproceedings {217486,
author = {Octavian Suciu and Radu Marginean and Yigitcan Kaya and Hal Daume III and Tudor Dumitras},
title = {When Does Machine Learning {FAIL}? Generalized Transferability for Evasion and Poisoning Attacks},
booktitle = {27th {USENIX} Security Symposium ({USENIX} Security 18)},
year = {2018},
isbn = {978-1-939133-04-5},
address = {Baltimore, MD},
pages = {1299--1316},
url = {https://www.usenix.org/conference/usenixsecurity18/presentation/suciu},
publisher = {{USENIX} Association},
month = aug,
}
@article{DBLP:journals/corr/abs-1909-09735,
  author  = {Aminollah Khormal ,Ahmed Abusnaina, Songqing Chen , DaeHun Nyang and Aziz Mohaisen},
  title     = {{COPYCAT:} Practical Adversarial Attacks on Visualization-Based Malware Detection},
  journal   = {CoRR},
  volume    = {abs/1909.09735},
  year      = {2019},
  url       = {http://arxiv.org/abs/1909.09735},
  archivePrefix = {arXiv},
  eprint    = {1909.09735},
  timestamp = {Fri, 27 Sep 2019 13:04:21 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1909-09735.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{orekondy2019knockoff,
  title={Knockoff nets: Stealing functionality of black-box models},
  author={Orekondy, Tribhuvanesh and Schiele, Bernt and Fritz, Mario},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4954--4963},
  year={2019}
}
@article{guo2019simple,
  title={Simple black-box adversarial attacks},
  author={Guo, Chuan and Gardner, Jacob R and You, Yurong and Wilson, Andrew Gordon and Weinberger, Kilian Q},
  journal={arXiv preprint arXiv:1905.07121},
  year={2019}
}
@inproceedings{andriushchenko2020square,
  title={Square attack: a query-efficient black-box adversarial attack via random search},
  author={Andriushchenko, Maksym and Croce, Francesco and Flammarion, Nicolas and Hein, Matthias},
  booktitle={European Conference on Computer Vision},
  pages={484--501},
  year={2020},
  organization={Springer}
}
@misc{carlini2017evaluating,
      title={Towards Evaluating the Robustness of Neural Networks}, 
      author={Nicholas Carlini and David Wagner},
      year={2017},
      eprint={1608.04644},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}
@misc{brendel2018decisionbased,
      title={Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models}, 
      author={Wieland Brendel and Jonas Rauber and Matthias Bethge},
      year={2018},
      eprint={1712.04248},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}
@misc{narodytska2016simple,
      title={Simple Black-Box Adversarial Perturbations for Deep Networks}, 
      author={Nina Narodytska and Shiva Prasad Kasiviswanathan},
      year={2016},
      eprint={1612.06299},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@inproceedings{khalid2019trisec,
  title={TrISec: training data-unaware imperceptible security attacks on deep neural networks},
  author={Khalid, Faiq and Hanif, Muhammad Abdullah and Rehman, Semeen and Ahmed, Rehan and Shafique, Muhammad},
  booktitle={2019 IEEE 25th International Symposium on On-Line Testing and Robust System Design (IOLTS)},
  pages={188--193},
  year={2019},
  organization={IEEE}
}
@inproceedings{zheng2019pointcloud,
  title={Pointcloud saliency maps},
  author={Zheng, Tianhang and Chen, Changyou and Yuan, Junsong and Li, Bo and Ren, Kui},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1598--1606},
  year={2019}
}
@article{li2018textbugger,
  title={Textbugger: Generating adversarial text against real-world applications},
  author={Li, Jinfeng and Ji, Shouling and Du, Tianyu and Li, Bo and Wang, Ting},
  journal={arXiv preprint arXiv:1812.05271},
  year={2018}
}
@misc{jagielski2018manipulating,
      title={Manipulating Machine Learning: Poisoning Attacks and Countermeasures for Regression Learning}, 
      author={Matthew Jagielski and Alina Oprea and Battista Biggio and Chang Liu and Cristina Nita-Rotaru and Bo Li},
      year={2018},
      eprint={1804.00308},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}
@misc{rozsa2016adversarial,
      title={Adversarial Diversity and Hard Positive Generation}, 
      author={Andras Rozsa and Ethan M. Rudd and Terrance E. Boult},
      year={2016},
      eprint={1605.01775},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{papernot2015limitations,
      title={The Limitations of Deep Learning in Adversarial Settings}, 
      author={Nicolas Papernot and Patrick McDaniel and Somesh Jha and Matt Fredrikson and Z. Berkay Celik and Ananthram Swami},
      year={2015},
      eprint={1511.07528},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}
@misc{moosavidezfooli2016deepfool,
      title={DeepFool: a simple and accurate method to fool deep neural networks}, 
      author={Seyed-Mohsen Moosavi-Dezfooli and Alhussein Fawzi and Pascal Frossard},
      year={2016},
      eprint={1511.04599},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{shen2020generalized,
      title={Generalized Adversarial Examples: Attacks and Defenses}, 
      author={Haojing Shen and Sihong Chen and Ran Wang and Xizhao Wang},
      year={2020},
      eprint={2011.14045},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{russakovsky2015imagenet,
      title={ImageNet Large Scale Visual Recognition Challenge}, 
      author={Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
      year={2015},
      eprint={1409.0575},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{simonyan2015deep,
      title={Very Deep Convolutional Networks for Large-Scale Image Recognition}, 
      author={Karen Simonyan and Andrew Zisserman},
      year={2015},
      eprint={1409.1556},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{huang2017adversarial,
      title={Adversarial Attacks on Neural Network Policies}, 
      author={Sandy Huang and Nicolas Papernot and Ian Goodfellow and Yan Duan and Pieter Abbeel},
      year={2017},
      eprint={1702.02284},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{kos2017delving,
      title={Delving into adversarial attacks on deep policies}, 
      author={Jernej Kos and Dawn Song},
      year={2017},
      eprint={1705.06452},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}
@misc{kos2017adversarial,
      title={Adversarial examples for generative models}, 
      author={Jernej Kos and Ian Fischer and Dawn Song},
      year={2017},
      eprint={1702.06832},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}
@misc{tabacof2016adversarial,
      title={Adversarial Images for Variational Autoencoders}, 
      author={Pedro Tabacof and Julia Tavares and Eduardo Valle},
      year={2016},
      eprint={1612.00155},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}
@misc{szegedy2014going,
      title={Going Deeper with Convolutions}, 
      author={Christian Szegedy and Wei Liu and Yangqing Jia and Pierre Sermanet and Scott Reed and Dragomir Anguelov and Dumitru Erhan and Vincent Vanhoucke and Andrew Rabinovich},
      year={2014},
      eprint={1409.4842},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@INPROCEEDINGS{7410480,
author={K. {He} and X. {Zhang} and S. {Ren} and J. {Sun}},
booktitle={2015 IEEE International Conference on Computer Vision (ICCV)}, title={Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification},
year={2015},
volume={},
number={},
pages={1026-1034},
doi={10.1109/ICCV.2015.123}
}
@inproceedings{arnab_cvpr_2018,
	title={On the Robustness of Semantic Segmentation Models to Adversarial Attacks},
	author={Arnab, Anurag and Miksik, Ondrej and Torr, Philip H. S.},
	booktitle={CVPR},
	year={2018}
}
@article{article,
author = {Yuan, Xiaoyong and He, Pan and Zhu, Qile and Bhat, Rajendra and Li, Xiaolin},
year = {2017},
month = {12},
pages = {},
title = {Adversarial Examples: Attacks and Defenses for Deep Learning}
}
@inproceedings{10.1145/2976749.2978392,
author = {Sharif, Mahmood and Bhagavatula, Sruti and Bauer, Lujo and Reiter, Michael K.},
title = {Accessorize to a Crime: Real and Stealthy Attacks on State-of-the-Art Face Recognition},
year = {2016},
isbn = {9781450341394},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2976749.2978392},
doi = {10.1145/2976749.2978392},
booktitle = {Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security},
pages = {1528–1540},
numpages = {13},
keywords = {face recognition, adversarial machine learning, neural networks, face detection},
location = {Vienna, Austria},
series = {CCS '16}
}
@misc{xie2017adversarial,
      title={Adversarial Examples for Semantic Segmentation and Object Detection}, 
      author={Cihang Xie and Jianyu Wang and Zhishuai Zhang and Yuyin Zhou and Lingxi Xie and Alan Yuille},
      year={2017},
      eprint={1703.08603},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{fischer2017adversarial,
      title={Adversarial Examples for Semantic Image Segmentation}, 
      author={Volker Fischer and Mummadi Chaithanya Kumar and Jan Hendrik Metzen and Thomas Brox},
      year={2017},
      eprint={1703.01101},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}
@misc{jia2017adversarial,
      title={Adversarial Examples for Evaluating Reading Comprehension Systems}, 
      author={Robin Jia and Percy Liang},
      year={2017},
      eprint={1707.07328},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{li2017understanding,
      title={Understanding Neural Networks through Representation Erasure}, 
      author={Jiwei Li and Will Monroe and Dan Jurafsky},
      year={2017},
      eprint={1612.08220},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{Grosse2017adversarial,
      title={Adversarial examples for malware detection},
      author= {K. Grosse, N. Papernot, P. Manoharan, M. Backes, and P. McDaniel},
      year={2017}
}
@ARTICLE{8611298,
  author={X. {Yuan} and P. {He} and Q. {Zhu} and X. {Li}},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Adversarial Examples: Attacks and Defenses for Deep Learning}, 
  year={2019},
  volume={30},
  number={9},
  pages={2805-2824},
  doi={10.1109/TNNLS.2018.2886017}
  }
  @misc{hu2017generating,
      title={Generating Adversarial Malware Examples for Black-Box Attacks Based on GAN}, 
      author={Weiwei Hu and Ying Tan},
      year={2017},
      eprint={1702.05983},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{simeone2018brief,
      title={A Very Brief Introduction to Machine Learning With Applications to Communication Systems}, 
      author={Osvaldo Simeone},
      year={2018},
      eprint={1808.02342},
      archivePrefix={arXiv},
      primaryClass={cs.IT}
}
@misc{biggio2013poisoning,
      title={Poisoning Attacks against Support Vector Machines}, 
      author={Battista Biggio and Blaine Nelson and Pavel Laskov},
      year={2013},
      eprint={1206.6389},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{xu2019dopa,
      title={DoPa: A Comprehensive CNN Detection Methodology against Physical Adversarial Attacks}, 
      author={Zirui Xu and Fuxun Yu and Xiang Chen},
      year={2019},
      eprint={1905.08790},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}
@misc{nguyen2018adversarial,
      title={Adversarial Attacks, Regression, and Numerical Stability Regularization}, 
      author={Andre T. Nguyen and Edward Raff},
      year={2018},
      eprint={1812.02885},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@article{article,
author = {Tabacof, Pedro and Valle, Eduardo},
year = {2015},
month = {10},
pages = {},
title = {Exploring the Space of Adversarial Images}
}
@misc{chen2019robust,
      title={Robust Decision Trees Against Adversarial Examples}, 
      author={Hongge Chen and Huan Zhang and Duane Boning and Cho-Jui Hsieh},
      year={2019},
      eprint={1902.10660},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{li2020adversarial,
      title={Adversarial Attack on Large Scale Graph}, 
      author={Jintang Li and Tao Xie and Liang Chen and Fenfang Xie and Xiangnan He and Zibin Zheng},
      year={2020},
      eprint={2009.03488},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{laidlaw2019functional,
      title={Functional Adversarial Attacks}, 
      author={Cassidy Laidlaw and Soheil Feizi},
      year={2019},
      eprint={1906.00001},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{machado2020adversarial,
      title={Adversarial Machine Learning in Image Classification: A Survey Towards the Defender's Perspective}, 
      author={Gabriel Resende Machado and Eugênio Silva and Ronaldo Ribeiro Goldschmidt},
      year={2020},
      eprint={2009.03728},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{yuan2018adversarial,
      title={Adversarial Examples: Attacks and Defenses for Deep Learning}, 
      author={Xiaoyong Yuan and Pan He and Qile Zhu and Xiaolin Li},
      year={2018},
      eprint={1712.07107},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{xu2019adversarial,
      title={Adversarial Attacks and Defenses in Images, Graphs and Text: A Review}, 
      author={Han Xu and Yao Ma and Haochen Liu and Debayan Deb and Hui Liu and Jiliang Tang and Anil K. Jain},
      year={2019},
      eprint={1909.08072},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@Article{app9050909,
AUTHOR = {Qiu, Shilin and Liu, Qihe and Zhou, Shijie and Wu, Chunjiang},
TITLE = {Review of Artificial Intelligence Adversarial Attack and Defense Technologies},
JOURNAL = {Applied Sciences},
VOLUME = {9},
YEAR = {2019},
NUMBER = {5},
ARTICLE-NUMBER = {909},
URL = {https://www.mdpi.com/2076-3417/9/5/909},
ISSN = {2076-3417},
DOI = {10.3390/app9050909}
}
@misc{zhao2020,
author = {Zhao, He and Le, Trung and Montague, Paul and Vel, Olivier and Abraham, Tamas and Phung, Dinh},
year = {2020},
month = {10},
pages = {},
title = {Towards Understanding Pixel Vulnerability under Adversarial Attacks for Images}
}
@misc{chakraborty2018adversarial,
      title={Adversarial Attacks and Defences: A Survey}, 
      author={Anirban Chakraborty and Manaar Alam and Vishal Dey and Anupam Chattopadhyay and Debdeep Mukhopadhyay},
      year={2018},
      eprint={1810.00069},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{tramer2020adaptive,
      title={On Adaptive Attacks to Adversarial Example Defenses}, 
      author={Florian Tramer and Nicholas Carlini and Wieland Brendel and Aleksander Madry},
      year={2020},
      eprint={2002.08347},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{carlini2017evaluating,
      title={Towards Evaluating the Robustness of Neural Networks}, 
      author={Nicholas Carlini and David Wagner},
      year={2017},
      eprint={1608.04644},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}
@article{Mei2015Zhu,
author = {Yuan, Xiaoyong and He, Pan and Zhu, Qile and Bhat, Rajendra and Li, Xiaolin},
year = {2017},
month = {12},
pages = {},
title = {Adversarial Examples: Attacks and Defenses for Deep Learning}
}
@article{9512facd37bba2ff1ece31900c08901bb011f1ce,
title = {Using Machine Teaching to Identify Optimal Training-Set Attacks on Machine Learners},
year = {2015},
url = {https://www.semanticscholar.org/paper/9512facd37bba2ff1ece31900c08901bb011f1ce},
author = {Shike Mei and Xiaojin Zhu}
}
@article{Xuezhou_Zhang_Laurent_Lessard,
title = {Online Data Poisoning Attacks},
year = {2020},
url = {https://www.semanticscholar.org/paper/9f57f27a7d022b30f82027fd8985ec4e6685f4ca},
author = {Xuezhou Zhang and Laurent Lessard},
}
@misc{madry2019deep,
      title={Towards Deep Learning Models Resistant to Adversarial Attacks}, 
      author={Aleksander Madry and Aleksandar Makelov and Ludwig Schmidt and Dimitris Tsipras and Adrian Vladu},
      year={2019},
      eprint={1706.06083},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@misc{chiang2019witchcraft,
      title={WITCHcraft: Efficient PGD attacks with random step size}, 
      author={Ping-Yeh Chiang and Jonas Geiping and Micah Goldblum and Tom Goldstein and Renkun Ni and Steven Reich and Ali Shafahi},
      year={2019},
      eprint={1911.07989},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{laugros2019adversarial,
      title={Are Adversarial Robustness and Common Perturbation Robustness Independent Attributes ?}, 
      author={Alfred Laugros and Alice Caplier and Matthieu Ospici},
      year={2019},
      eprint={1909.02436},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{laidlaw2021perceptual,
      title={Perceptual Adversarial Robustness: Defense Against Unseen Threat Models}, 
      author={Cassidy Laidlaw and Sahil Singla and Soheil Feizi},
      year={2021},
      eprint={2006.12655},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{wang2020defending,
      title={Defending against Adversarial Attack towards Deep Neural Networks via Collaborative Multi-task Training}, 
      author={Derek Wang and Chaoran Li and Sheng Wen and Surya Nepal and Yang Xiang},
      year={2020},
      eprint={1803.05123},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{moosavidezfooli2016deepfool,
      title={DeepFool: a simple and accurate method to fool deep neural networks}, 
      author={Seyed-Mohsen Moosavi-Dezfooli and Alhussein Fawzi and Pascal Frossard},
      year={2016},
      eprint={1511.04599},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{feinman2017detecting,
      title={Detecting Adversarial Samples from Artifacts}, 
      author={Reuben Feinman and Ryan R. Curtin and Saurabh Shintre and Andrew B. Gardner},
      year={2017},
      eprint={1703.00410},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}
@misc{brown2018adversarial,
      title={Adversarial Patch}, 
      author={Tom B. Brown and Dandelion Mané and Aurko Roy and Martín Abadi and Justin Gilmer},
      year={2018},
      eprint={1712.09665},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{dou2018mathematical,
      title={Mathematical Analysis of Adversarial Attacks}, 
      author={Zehao Dou and Stanley J. Osher and Bao Wang},
      year={2018},
      eprint={1811.06492},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{moosavidezfooli2017universal,
      title={Universal adversarial perturbations}, 
      author={Seyed-Mohsen Moosavi-Dezfooli and Alhussein Fawzi and Omar Fawzi and Pascal Frossard},
      year={2017},
      eprint={1610.08401},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{andriushchenko2020square,
      title={Square Attack: a query-efficient black-box adversarial attack via random search}, 
      author={Maksym Andriushchenko and Francesco Croce and Nicolas Flammarion and Matthias Hein},
      year={2020},
      eprint={1912.00049},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
  @misc{zhao2019unsupervised,
      title={Unsupervised Adversarial Attacks on Deep Feature-based Retrieval with GAN}, 
      author={Guoping Zhao and Mingyu Zhang and Jiajun Liu and Ji-Rong Wen},
      year={2019},
      eprint={1907.05793},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@article{Su_2019,
   title={One Pixel Attack for Fooling Deep Neural Networks},
   volume={23},
   ISSN={1941-0026},
   url={http://dx.doi.org/10.1109/TEVC.2019.2890858},
   DOI={10.1109/tevc.2019.2890858},
   number={5},
   journal={IEEE Transactions on Evolutionary Computation},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Su, Jiawei and Vargas, Danilo Vasconcellos and Sakurai, Kouichi},
   year={2019},
   month={Oct},
   pages={828–841}
}
@misc{gowal2019effectiveness,
      title={On the Effectiveness of Interval Bound Propagation for Training Verifiably Robust Models}, 
      author={Sven Gowal and Krishnamurthy Dvijotham and Robert Stanforth and Rudy Bunel and Chongli Qin and Jonathan Uesato and Relja Arandjelovic and Timothy Mann and Pushmeet Kohli},
      year={2019},
      eprint={1810.12715},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{croce2021mind,
      title={Mind the box: $l_1$-APGD for sparse adversarial attacks on image classifiers}, 
      author={Francesco Croce and Matthias Hein},
      year={2021},
      eprint={2103.01208},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{pintor2021fast,
      title={Fast Minimum-norm Adversarial Attacks through Adaptive Norm Constraints}, 
      author={Maura Pintor and Fabio Roli and Wieland Brendel and Battista Biggio},
      year={2021},
      eprint={2102.12827},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{schwinn2020rapid,
      title={Towards Rapid and Robust Adversarial Training with One-Step Attacks}, 
      author={Leo Schwinn and René Raab and Björn Eskofier},
      year={2020},
      eprint={2002.10097},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{s2020singlestep,
      title={Single-step Adversarial training with Dropout Scheduling}, 
      author={Vivek B. S. and R. Venkatesh Babu},
      year={2020},
      eprint={2004.08628},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@inproceedings{Sharif16AdvML,
  author={Mahmood Sharif and Sruti Bhagavatula and Lujo Bauer and Michael K. Reiter},
  title={Accessorize to a crime: {R}eal and stealthy attacks on state-of-the-art face recognition},
  booktitle={Proceedings of the 23rd ACM SIGSAC Conference on Computer and Communications Security},
  year=2016
} 
@misc{ilyas2018blackbox,
      title={Black-box Adversarial Attacks with Limited Queries and Information}, 
      author={Andrew Ilyas and Logan Engstrom and Anish Athalye and Jessy Lin},
      year={2018},
      eprint={1804.08598},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{sarkar2017upset,
      title={UPSET and ANGRI : Breaking High Performance Image Classifiers}, 
      author={Sayantan Sarkar and Ankan Bansal and Upal Mahbub and Rama Chellappa},
      year={2017},
      eprint={1707.01159},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{cisse2017houdini,
      title={Houdini: Fooling Deep Structured Prediction Models}, 
      author={Moustapha Cisse and Yossi Adi and Natalia Neverova and Joseph Keshet},
      year={2017},
      eprint={1707.05373},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}
@article{Su_2019,
   title={One Pixel Attack for Fooling Deep Neural Networks},
   volume={23},
   ISSN={1941-0026},
   url={http://dx.doi.org/10.1109/TEVC.2019.2890858},
   DOI={10.1109/tevc.2019.2890858},
   number={5},
   journal={IEEE Transactions on Evolutionary Computation},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Su, Jiawei and Vargas, Danilo Vasconcellos and Sakurai, Kouichi},
   year={2019},
   month={Oct},
   pages={828–841}
}
@misc{moon2019parsimonious,
      title={Parsimonious Black-Box Adversarial Attacks via Efficient Combinatorial Optimization}, 
      author={Seungyong Moon and Gaon An and Hyun Oh Song},
      year={2019},
      eprint={1905.06635},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{meunier2019efficient,
      title={Yet another but more efficient black-box adversarial attack: tiling and evolution strategies}, 
      author={Laurent Meunier and Jamal Atif and Olivier Teytaud},
      year={2019},
      eprint={1910.02244},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{ilyas2019prior,
      title={Prior Convictions: Black-Box Adversarial Attacks with Bandits and Priors}, 
      author={Andrew Ilyas and Logan Engstrom and Aleksander Madry},
      year={2019},
      eprint={1807.07978},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}
@misc{baluja2017adversarial,
      title={Adversarial Transformation Networks: Learning to Generate Adversarial Examples}, 
      author={Shumeet Baluja and Ian Fischer},
      year={2017},
      eprint={1703.09387},
      archivePrefix={arXiv},
      primaryClass={cs.NE}
}
@inproceedings{
al-dujaili2020sign,
title={Sign Bits Are All You Need for Black-Box Attacks},
author={Abdullah Al-Dujaili and Una-May O'Reilly},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=SygW0TEFwH}
}
@article{Wierstra2014,
author = {Wierstra, Daan and Schaul, Tom and Glasmachers, Tobias and Sun, Yi and Peters, Jan and Schmidhuber, J\"{u}rgen},
title = {Natural Evolution Strategies},
year = {2014}
}
@inproceedings{
liu2018signsgd,
title={sign{SGD} via Zeroth-Order Oracle},
author={Sijia Liu and Pin-Yu Chen and Xiangyi Chen and Mingyi Hong},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=BJe-DsC5Fm},
}
@misc{gao2021scaleadv,
      title={Scale-Adv: A Joint Attack on Image-Scaling and Machine Learning Classifiers}, 
      author={Yue Gao and Kassem Fawaz},
      year={2021},
      eprint={2104.08690},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{ghiasi2020breaking,
      title={Breaking certified defenses: Semantic adversarial examples with spoofed robustness certificates}, 
      author={Amin Ghiasi and Ali Shafahi and Tom Goldstein},
      year={2020},
      eprint={2003.08937},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{zhang2019stable,
      title={Towards Stable and Efficient Training of Verifiably Robust Neural Networks}, 
      author={Huan Zhang and Hongge Chen and Chaowei Xiao and Sven Gowal and Robert Stanforth and Bo Li and Duane Boning and Cho-Jui Hsieh},
      year={2019},
      eprint={1906.06316},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{ghiasi2020breaking,
      title={Breaking certified defenses: Semantic adversarial examples with spoofed robustness certificates}, 
      author={Amin Ghiasi and Ali Shafahi and Tom Goldstein},
      year={2020},
      eprint={2003.08937},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{singla2020secondorder,
      title={Second-Order Provable Defenses against Adversarial Attacks}, 
      author={Sahil Singla and Soheil Feizi},
      year={2020},
      eprint={2006.00731},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{yuan2020gradientfree,
      title={Gradient-Free Adversarial Attacks for Bayesian Neural Networks}, 
      author={Matthew Yuan and Matthew Wicker and Luca Laurenti},
      year={2020},
      eprint={2012.12640},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{laidlaw2019functional,
      title={Functional Adversarial Attacks}, 
      author={Cassidy Laidlaw and Soheil Feizi},
      year={2019},
      eprint={1906.00001},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{ross2017improving,
      title={Improving the Adversarial Robustness and Interpretability of Deep Neural Networks by Regularizing their Input Gradients}, 
      author={Andrew Slavin Ross and Finale Doshi-Velez},
      year={2017},
      eprint={1711.09404},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@article{Ma2021UnderstandingAttacksonMedicalImage,
   title={Understanding adversarial attacks on deep learning based medical image analysis systems},
   volume={110},
   ISSN={0031-3203},
   url={http://dx.doi.org/10.1016/j.patcog.2020.107332}
}
@misc{zhang2021survey,
      title={A Survey On Universal Adversarial Attack}, 
      author={Chaoning Zhang and Philipp Benz and Chenguo Lin and Adil Karjauv and Jing Wu and In So Kweon},
      year={2021},
      eprint={2103.01498},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{mao2020composite,
      title={Composite Adversarial Attacks}, 
      author={Xiaofeng Mao and Yuefeng Chen and Shuhui Wang and Hang Su and Yuan He and Hui Xue},
      year={2020},
      eprint={2012.05434},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}
@article{REN2020346,
title = {Adversarial Attacks and Defenses in Deep Learning},
journal = {Engineering},
volume = {6},
number = {3},
pages = {346-360},
year = {2020},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2019.12.012},
url = {https://www.sciencedirect.com/science/article/pii/S209580991930503X}
}
@article{xu2020adversarial,
  title={Adversarial attacks and defenses in images, graphs and text: A review},
  author={Xu, Han and Ma, Yao and Liu, Hao-Chen and Deb, Debayan and Liu, Hui and Tang, Ji-Liang and Jain, Anil K},
  journal={International Journal of Automation and Computing},
  volume={17},
  number={2},
  pages={151--178},
  year={2020},
  publisher={Springer}
}
@misc{bhattad2020unrestricted,
      title={Unrestricted Adversarial Examples via Semantic Manipulation}, 
      author={Anand Bhattad and Min Jin Chong and Kaizhao Liang and Bo Li and D. A. Forsyth},
      year={2020},
      eprint={1904.06347},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@inproceedings{quiring2020adversarial,
  title={Adversarial preprocessing: Understanding and preventing image-scaling attacks in machine learning},
  author={Quiring, Erwin and Klein, David and Arp, Daniel and Johns, Martin and Rieck, Konrad},
  booktitle={29th $\{$USENIX$\}$ Security Symposium ($\{$USENIX$\}$ Security 20)},
  pages={1363--1380},
  year={2020}
}
@inproceedings{maini2020adversarial,
  title={Adversarial robustness against the union of multiple perturbation models},
  author={Maini, Pratyush and Wong, Eric and Kolter, Zico},
  booktitle={International Conference on Machine Learning},
  pages={6640--6650},
  year={2020},
  organization={PMLR}
}
@misc{laidlaw2021perceptual,
      title={Perceptual Adversarial Robustness: Defense Against Unseen Threat Models}, 
      author={Cassidy Laidlaw and Sahil Singla and Soheil Feizi},
      year={2021},
      eprint={2006.12655},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{demontis2019adversarial,
      title={Why Do Adversarial Attacks Transfer? Explaining Transferability of Evasion and Poisoning Attacks}, 
      author={Ambra Demontis and Marco Melis and Maura Pintor and Matthew Jagielski and Battista Biggio and Alina Oprea and Cristina Nita-Rotaru and Fabio Roli},
      year={2019},
      eprint={1809.02861},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{szegedy2014intriguing,
      title={Intriguing properties of neural networks}, 
      author={Christian Szegedy and Wojciech Zaremba and Ilya Sutskever and Joan Bruna and Dumitru Erhan and Ian Goodfellow and Rob Fergus},
      year={2014},
      eprint={1312.6199},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@article{ozdag2018adversarial,
  title={Adversarial attacks and defenses against deep neural networks: a survey},
  author={Ozdag, Mesut},
  journal={Procedia Computer Science},
  volume={140},
  pages={152--161},
  year={2018},
  publisher={Elsevier}
}
@INPROCEEDINGS{DengYin2020,
  author={Deng, Yingpeng and Karam, Lina J.},
  booktitle={2020 IEEE International Conference on Image Processing (ICIP)}, 
  title={Universal Adversarial Attack Via Enhanced Projected Gradient Descent}, 
  year={2020},
  volume={},
  number={},
  pages={1241-1245},
  doi={10.1109/ICIP40778.2020.9191288}
  }
  @misc{dong2018boosting,
      title={Boosting Adversarial Attacks with Momentum}, 
      author={Yinpeng Dong and Fangzhou Liao and Tianyu Pang and Hang Su and Jun Zhu and Xiaolin Hu and Jianguo Li},
      year={2018},
      eprint={1710.06081},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{che2019new,
      title={A New Ensemble Adversarial Attack Powered by Long-term Gradient Memories}, 
      author={Zhaohui Che and Ali Borji and Guangtao Zhai and Suiyi Ling and Jing Li and Patrick Le Callet},
      year={2019},
      eprint={1911.07682},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{huang2020blackbox,
      title={Black-Box Adversarial Attack with Transferable Model-based Embedding}, 
      author={Zhichao Huang and Tong Zhang},
      year={2020},
      eprint={1911.07140},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{koh2018stronger,
      title={Stronger Data Poisoning Attacks Break Data Sanitization Defenses}, 
      author={Pang Wei Koh and Jacob Steinhardt and Percy Liang},
      year={2018},
      eprint={1811.00741},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}
@misc{dong2019evading,
      title={Evading Defenses to Transferable Adversarial Examples by Translation-Invariant Attacks}, 
      author={Yinpeng Dong and Tianyu Pang and Hang Su and Jun Zhu},
      year={2019},
      eprint={1904.02884},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{yang2017generative,
      title={Generative Poisoning Attack Method Against Neural Networks}, 
      author={Chaofei Yang and Qing Wu and Hai Li and Yiran Chen},
      year={2017},
      eprint={1703.01340},
      archivePrefix={arXiv},
      primaryClass={cs.CR}
}
@article{SijiaSignSGD2019,
  author = {Sijia Liu and Pin-Yu Chen and Xiangyi Chen and Mingyi Hong},
   title = {SIGNSGD VIA ZEROTH-ORDER ORACLE},
}
@article{pmlr-v119-croce20a,
  title = {Minimally distorted Adversarial Examples with a Fast Adaptive Boundary Attack},
  author = {Croce, Francesco and Hein, Matthias},
  booktitle = {Proceedings of the 37th International Conference on Machine Learning},
  pages = {2196--2205},
  year = {2020},
  editor = {III, Hal Daumé and Singh, Aarti},
  volume = {119},
  series = {Proceedings of Machine Learning Research},
  month = {13--18 Jul},
  publisher = {PMLR},
  pdf = {http://proceedings.mlr.press/v119/croce20a/croce20a.pdf},
  url = {https://proceedings.mlr.press/v119/croce20a.html}
}
@article{mao2020composite,
  title={Composite Adversarial Attacks},
  author={Mao, Xiaofeng and Chen, Yuefeng and Wang, Shuhui and Su, Hang and He, Yuan and Xue, Hui},
  journal={arXiv preprint arXiv:2012.05434},
  year={2020}
}
@misc{ghiasi2020breaking,
      title={Breaking certified defenses: Semantic adversarial examples with spoofed robustness certificates}, 
      author={Amin Ghiasi and Ali Shafahi and Tom Goldstein},
      year={2020},
      eprint={2003.08937},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@article{Biggio2012,
   author = {Battista Biggio and Blaine Nelson and Pavel Laskov},
   title = {Poisoning Attacks against Support Vector Machines},
   year = {2012},
}
@misc{zhu2019transferable,
      title={Transferable Clean-Label Poisoning Attacks on Deep Neural Nets}, 
      author={Chen Zhu and W. Ronny Huang and Ali Shafahi and Hengduo Li and Gavin Taylor and Christoph Studer and Tom Goldstein},
      year={2019},
      eprint={1905.05897},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}
@article{munoz2019poisoning,
  title={Poisoning attacks with generative adversarial nets},
  author={Mu{\~n}oz-Gonz{\'a}lez, Luis and Pfitzner, Bjarne and Russo, Matteo and Carnerero-Cano, Javier and Lupu, Emil C},
  journal={arXiv preprint arXiv:1906.07773},
  year={2019}
}
@inproceedings{biggio2011support,
  title={Support vector machines under adversarial label noise},
  author={Biggio, Battista and Nelson, Blaine and Laskov, Pavel},
  booktitle={Asian conference on machine learning},
  pages={97--112},
  year={2011},
  organization={PMLR}
}
@inproceedings{jagielski2018manipulating,
  title={Manipulating machine learning: Poisoning attacks and countermeasures for regression learning},
  author={Jagielski, Matthew and Oprea, Alina and Biggio, Battista and Liu, Chang and Nita-Rotaru, Cristina and Li, Bo},
  booktitle={2018 IEEE Symposium on Security and Privacy (SP)},
  pages={19--35},
  year={2018},
  organization={IEEE}
}
@article{WANG2021,
title = {Poisoning attacks and countermeasures in intelligent networks: Status quo and prospects},
journal = {Digital Communications and Networks},
year = {2021},
issn = {2352-8648},
doi = {https://doi.org/10.1016/j.dcan.2021.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S235286482100050X},
author = {Chen Wang and Jian Chen and Yang Yang and Xiaoqiang Ma and Jiangchuan Liu},
keywords = {Machine learning, Poisoning attack, Intelligent networks, Security threat}
}
@INPROCEEDINGS{8418594,  author={Jagielski, Matthew and Oprea, Alina and Biggio, Battista and Liu, Chang and Nita-Rotaru, Cristina and Li, Bo},  booktitle={2018 IEEE Symposium on Security and Privacy (SP)},   title={Manipulating Machine Learning: Poisoning Attacks and Countermeasures for Regression Learning},   year={2018},  volume={},  number={},  pages={19-35},  doi={10.1109/SP.2018.00057}
}
@InProceedings{Poisoning-Biggio2014,
author="Biggio, Battista
and Bul{\`o}, Samuel Rota
and Pillai, Ignazio
and Mura, Michele
and Mequanint, Eyasu Zemene
and Pelillo, Marcello
and Roli, Fabio",
editor="Fr{\"a}nti, Pasi
and Brown, Gavin
and Loog, Marco
and Escolano, Francisco
and Pelillo, Marcello",
title="Poisoning Complete-Linkage Hierarchical Clustering",
booktitle="Structural, Syntactic, and Statistical Pattern Recognition",
year="2014",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="42--52"}
}
@article{MetaPosion2020,
   author = {W Ronny Huang and Jonas Geiping and Liam Fowl and Gavin Taylor and Tom Goldstein},
   title = {MetaPoison: Practical General-purpose Clean-label Data Poisoning},
   url = {https://www.github.com/},
}
@article{UAP2022,
   title = {A Survey on Universal Adversarial Attack},
   url = {https://bit.ly/2SbQlLG.},
}
@misc{aghakhani2021bullseye,
      title={Bullseye Polytope: A Scalable Clean-Label Poisoning Attack with Improved Transferability}, 
      author={Hojjat Aghakhani and Dongyu Meng and Yu-Xiang Wang and Christopher Kruegel and Giovanni Vigna},
      year={2021},
      eprint={2005.00191},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@article{Taheri2020,
   author = {Rahim Taheri and Reza Javidan and Mohammad Shojafar and Zahra Pooranian and Ali Miri and Mauro Conti},
   doi = {10.1007/S00521-020-04831-9/TABLES/4},
   issn = {14333058},
   issue = {18},
   journal = {Neural Computing and Applications},
   keywords = {Adversarial example,Adversarial machine learning (AML),Deep learning,Label flipping attacks,Malware detection,Semi-supervised defense (SSD)},
   month = {9},
   pages = {14781-14800},
   publisher = {Springer Science and Business Media Deutschland GmbH},
   title = {On defending against label flipping attacks on malware detection systems},
   volume = {32},
   url = {https://link.springer.com/article/10.1007/s00521-020-04831-9},
   year = {2020},
}
@misc{aghakhani2021venomave,
      title={VenoMave: Targeted Poisoning Against Speech Recognition}, 
      author={Hojjat Aghakhani and Lea Schönherr and Thorsten Eisenhofer and Dorothea Kolossa and Thorsten Holz and Christopher Kruegel and Giovanni Vigna},
      year={2021},
      eprint={2010.10682},
      archivePrefix={arXiv},
      primaryClass={cs.SD}
}
@misc{wallace2021concealed,
      title={Concealed Data Poisoning Attacks on NLP Models}, 
      author={Eric Wallace and Tony Z. Zhao and Shi Feng and Sameer Singh},
      year={2021},
      eprint={2010.12563},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{zhang2019data,
      title={Data Poisoning Attack against Knowledge Graph Embedding}, 
      author={Hengtong Zhang and Tianhang Zheng and Jing Gao and Chenglin Miao and Lu Su and Yaliang Li and Kui Ren},
      year={2019},
      eprint={1904.12052},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@inproceedings{PCA-Poisoning2009,
author = {Rubinstein, Benjamin I.P. and Nelson, Blaine and Huang, Ling and Joseph, Anthony D. and Lau, Shing-hon and Rao, Satish and Taft, Nina and Tygar, J. D.},
title = {ANTIDOTE: Understanding and Defending against Poisoning of Anomaly Detectors},
year = {2009},
isbn = {9781605587714},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1644893.1644895},
doi = {10.1145/1644893.1644895},
booktitle = {Proceedings of the 9th ACM SIGCOMM Conference on Internet Measurement},
pages = {1–14},
numpages = {14},
keywords = {network traffic analysis, adversarial learning, principal components analysis, robust statistics},
location = {Chicago, Illinois, USA},
series = {IMC '09}
}
@inproceedings{
fowl2021adversarial,
title={Adversarial Examples Make Strong Poisons},
author={Liam H Fowl and Micah Goldblum and Ping-yeh Chiang and Jonas Geiping and Wojciech Czaja and Tom Goldstein},
booktitle={Advances in Neural Information Processing Systems},
editor={A. Beygelzimer and Y. Dauphin and P. Liang and J. Wortman Vaughan},
year={2021},
url={https://openreview.net/forum?id=DE8MOQIgFTK}
}
@article{41-Biggio2013,
   author = {Battista Biggio and Ignazio Pillai and Samuel Rota Bulò and Davide Ariu and Marcello Pelillo and Fabio Roli},
   doi = {10.1145/2517312.2517321},
   isbn = {9781450324885},
   keywords = {D46 [Security and Protection]: Invasive software (eg, viruses, worms, Trojan horses),G3 [Probability and Statis-tics]: Statistical computing,I51 [Models]: Statistical,I52 [Design Methodology]: Clustering design and eval-uation,I53 [Clustering]: Algorithms General Terms Security, Clustering Keywords Adversarial learning, Unsupervised Learning, Clustering, Se-curity Evaluation, Computer Security, Malware Detection},
   title = {Is Data Clustering in Adversarial Settings Secure?},
   url = {http://dx.doi.org/10.1145/2517312.2517321},
   year = {2013},
}
@article{shorten2019survey,
  title={A survey on image data augmentation for deep learning},
  author={Shorten, Connor and Khoshgoftaar, Taghi M},
  journal={Journal of big data},
  volume={6},
  number={1},
  pages={1--48},
  year={2019},
  publisher={Springer}
}
@misc{PoisonFrogs,
  doi = {10.48550/ARXIV.1804.00792},
  url = {https://arxiv.org/abs/1804.00792},
  author = {Shafahi, Ali and Huang, W. Ronny and Najibi, Mahyar and Suciu, Octavian and Studer, Christoph and Dumitras, Tudor and Goldstein, Tom},
  keywords = {Machine Learning (cs.LG), Cryptography and Security (cs.CR), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks},
  publisher = {arXiv},
  year = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@misc{https://doi.org/10.48550/arxiv.1804.00792,
doi = {10.48550/ARXIV.1804.00792},
url = {https://arxiv.org/abs/1804.00792},
author = {Shafahi, Ali and Huang, W. Ronny and Najibi, Mahyar and Suciu, Octavian and Studer, Christoph and Dumitras, Tudor and Goldstein, Tom},
keywords = {Machine Learning (cs.LG), Cryptography and Security (cs.CR), Computer Vision and Pattern Recognition (cs.CV), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
title = {Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks},
publisher = {arXiv},
year = {2018},
copyright = {arXiv.org perpetual, non-exclusive license}
}
@misc{https://doi.org/10.48550/arxiv.1708.06733,
  doi = {10.48550/ARXIV.1708.06733},
  url = {https://arxiv.org/abs/1708.06733},
  author = {Gu, Tianyu and Dolan-Gavitt, Brendan and Garg, Siddharth},
  keywords = {Cryptography and Security (cs.CR), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain},
  publisher = {arXiv},
  year = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{mahloujifar19a,
  title = {Can Adversarially Robust Learning LeverageComputational Hardness?},
  author = {Mahloujifar, Saeed and Mahmoody, Mohammad},
  booktitle = {Proceedings of the 30th International Conference on Algorithmic Learning Theory},
  pages = {581--609},
  year = {2019},
  editor = {Garivier, Aurélien and Kale, Satyen},
  volume = {98},
  series = {Proceedings of Machine Learning Research},
  month = {22--24 Mar},
  publisher = {PMLR},
  pdf = {http://proceedings.mlr.press/v98/mahloujifar19a/mahloujifar19a.pdf},
  url = {https://proceedings.mlr.press/v98/mahloujifar19a.html}
}
@misc{Gu_Tianyu,
  doi = {10.48550/ARXIV.1708.06733},
  url = {https://arxiv.org/abs/1708.06733},
  author = {Gu, Tianyu and Dolan-Gavitt, Brendan and Garg, Siddharth},
  keywords = {Cryptography and Security (cs.CR), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain},
  publisher = {arXiv},
  year = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
